{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd870419",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'build_model' from 'model' (c:\\Users\\User\\Desktop\\Medical-Image-Classification\\src\\model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m sys.path.append(os.path.abspath(\u001b[33m\"\u001b[39m\u001b[33m../src/\u001b[39m\u001b[33m\"\u001b[39m))  \n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_dataloaders\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_model\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_model\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevaluate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m test_model\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'build_model' from 'model' (c:\\Users\\User\\Desktop\\Medical-Image-Classification\\src\\model.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src/\"))  \n",
    "from data_loader import get_dataloaders\n",
    "from model import build_model\n",
    "from train import train_model\n",
    "from evaluate import test_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3a5907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd2ebf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_dataloaders' from 'src.data_loader' (c:\\Users\\User\\Desktop\\Medical-Image-Classification\\src\\data_loader.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_dataloaders\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Define paths\u001b[39;00m\n\u001b[32m      3\u001b[39m data_dir = \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m  \n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'get_dataloaders' from 'src.data_loader' (c:\\Users\\User\\Desktop\\Medical-Image-Classification\\src\\data_loader.py)"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "data_dir = \"data\"  \n",
    "batch_size = 32\n",
    "img_size = 224\n",
    "\n",
    "# Load data\n",
    "train_loader, val_loader, test_loader, class_names = get_dataloaders(\n",
    "    data_dir=data_dir,\n",
    "    batch_size=batch_size,\n",
    "    img_size=img_size\n",
    ")\n",
    "\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454bb0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(num_classes=len(class_names), pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef22da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 0.001\n",
    "\n",
    "model, history = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    device, \n",
    "    epochs=epochs, \n",
    "    lr=lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6645e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, test_loader, device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac637b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"chest_xray_model.pth\")\n",
    "print(\"âœ… Model saved as chest_xray_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "def generate_gradcam(model, image, target_class, device, layer_name=\"layer4\"):\n",
    "    \"\"\"\n",
    "    Generate Grad-CAM heatmap for a given image and class.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    gradients = []\n",
    "    activations = []\n",
    "\n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        gradients.append(grad_output[0].detach())\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        activations.append(output.detach())\n",
    "\n",
    "    # Register hooks\n",
    "    target_layer = dict([*model.named_modules()])[layer_name]\n",
    "    forward_handle = target_layer.register_forward_hook(forward_hook)\n",
    "    backward_handle = target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    # Forward pass\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    output = model(image)\n",
    "    pred_class = output.argmax(dim=1).item()\n",
    "\n",
    "    # Backward pass for target class\n",
    "    model.zero_grad()\n",
    "    class_score = output[0, target_class]\n",
    "    class_score.backward()\n",
    "\n",
    "    # Extract gradients and activations\n",
    "    grads = gradients[0].cpu().numpy()[0]\n",
    "    acts = activations[0].cpu().numpy()[0]\n",
    "\n",
    "    # Compute weights\n",
    "    weights = np.mean(grads, axis=(1, 2))\n",
    "    cam = np.zeros(acts.shape[1:], dtype=np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * acts[i]\n",
    "\n",
    "    # Normalize\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cv2.resize(cam, (224, 224))\n",
    "    cam = cam - np.min(cam)\n",
    "    cam = cam / np.max(cam)\n",
    "\n",
    "    # Clean up hooks\n",
    "    forward_handle.remove()\n",
    "    backward_handle.remove()\n",
    "\n",
    "    return cam, pred_class\n",
    "\n",
    "\n",
    "def show_gradcam(model, img_path, class_names, device):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485], [0.229])\n",
    "    ])\n",
    "\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    pil_img = transforms.ToPILImage()(img_rgb)\n",
    "    input_tensor = transform(pil_img)\n",
    "\n",
    "    # Choose target class (for demo, use model prediction)\n",
    "    _, pred_class = torch.max(model(input_tensor.unsqueeze(0).to(device)), 1)\n",
    "    cam, predicted_class = generate_gradcam(model, input_tensor, target_class=pred_class.item(), device=device)\n",
    "\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    img_norm = np.float32(img_rgb) / 255\n",
    "    overlay = heatmap + img_norm\n",
    "    overlay = overlay / np.max(overlay)\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1,3,1); plt.imshow(img_rgb); plt.title(\"Original X-ray\"); plt.axis(\"off\")\n",
    "    plt.subplot(1,3,2); plt.imshow(cam, cmap=\"jet\"); plt.title(\"Grad-CAM Heatmap\"); plt.axis(\"off\")\n",
    "    plt.subplot(1,3,3); plt.imshow(overlay); plt.title(f\"Prediction: {class_names[pred_class]}\"); plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
